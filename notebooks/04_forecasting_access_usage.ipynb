{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Task 4: Forecasting Access and Usage\n", "\n", "Objective: Forecast Account Ownership (Access) and Digital Payment Usage for 2025\u20132027 with baseline trend, event-augmented model, scenarios, and uncertainty."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Setup"]}, {"cell_type": "code", "metadata": {}, "source": ["import pandas as pd\n", "import numpy as np\n", "from pathlib import Path\n", "import matplotlib.pyplot as plt\n", "plt.rcParams['figure.figsize']=(9,4)\n", "DATA_PATH = Path('../data/processed/ethiopia_fi_unified_data_combined.csv')\n", "df = pd.read_csv(DATA_PATH)\n", "observations = df[df['record_type']=='observation'].copy()\n", "events = df[df['record_type']=='event'].copy()\n", "impact_links = df[df['record_type']=='impact_link'].copy()\n", "print(f'Loaded observations={len(observations)}, events={len(events)}, links={len(impact_links)}')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Targets"]}, {"cell_type": "code", "metadata": {}, "source": ["# Access: ACC_OWNERSHIP (%)\n", "acc = observations[observations['indicator_code']=='ACC_OWNERSHIP'].copy()\n", "acc['observation_date'] = pd.to_datetime(acc['observation_date'], errors='coerce')\n", "acc = acc.dropna(subset=['observation_date'])\n", "acc['year'] = acc['observation_date'].dt.year\n", "train_acc = acc.groupby('year')['value_numeric'].mean().dropna().reset_index(name='value')\n", "print('ACC_OWNERSHIP points:', train_acc.shape[0], '\n', train_acc)\n", "\n", "# Usage (%): attempt to find a percent indicator; else use USG_P2P_COUNT as a proxy (volume)\n", "cand = observations[observations['indicator_code'].str.contains('DIG|PAY', case=False, na=False)].copy()\n", "cand_cols = cand['indicator_code'].value_counts()\n", "print('Candidate usage indicators:', list(cand_cols.index[:10]))\n", "usage_pct_codes = [c for c in cand_cols.index if 'PCT' in c or 'SHARE' in c or 'RATE' in c]\n", "usage_pct = None\n", "if usage_pct_codes:\n", "    code = usage_pct_codes[0]\n", "    up = observations[observations['indicator_code']==code].copy()\n", "    up['observation_date'] = pd.to_datetime(up['observation_date'], errors='coerce')\n", "    up = up.dropna(subset=['observation_date'])\n", "    up['year'] = up['observation_date'].dt.year\n", "    usage_pct = up.groupby('year')['value_numeric'].mean().dropna().reset_index(name='value')\n", "    usage_label = f'DIGITAL_PAY_USAGE_PCT ({code})'\n", "else:\n", "    # Proxy with USG_P2P_COUNT (transaction count) as usage volume\n", "    p2p = observations[observations['indicator_code']=='USG_P2P_COUNT'].copy()\n", "    p2p['observation_date'] = pd.to_datetime(p2p['observation_date'], errors='coerce')\n", "    p2p = p2p.dropna(subset=['observation_date'])\n", "    p2p['year'] = p2p['observation_date'].dt.year\n", "    usage_pct = p2p.groupby('year')['value_numeric'].sum().dropna().reset_index(name='value')\n", "    usage_label = 'USG_P2P_COUNT (usage proxy)'\n", "print('Usage series:', usage_label, '\n', usage_pct)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Trend Fit + Simple Uncertainty"]}, {"cell_type": "code", "metadata": {}, "source": ["def fit_trend(train_df):\n", "    years = train_df['year'].values.astype(float)\n", "    y = train_df['value'].values.astype(float)\n", "    A = np.vstack([years, np.ones_like(years)]).T\n", "    slope, intercept = np.linalg.lstsq(A, y, rcond=None)[0]\n", "    pred = slope*years + intercept\n", "    resid = y - pred\n", "    rmse = float(np.sqrt(np.mean(resid**2)))\n", "    return {'slope':float(slope),'intercept':float(intercept),'rmse':rmse}\n", "\n", "def predict_years(model, years):\n", "    years = np.array(years, dtype=float)\n", "    yhat = model['slope']*years + model['intercept']\n", "    lo = yhat - 1.96*model['rmse']\n", "    hi = yhat + 1.96*model['rmse']\n", "    return yhat, lo, hi\n", "\n", "acc_model = fit_trend(train_acc)\n", "usage_model = fit_trend(usage_pct)\n", "print('ACC model:', acc_model)\n", "print('USG/Digital model:', usage_model)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Event Effects (from impact_links)"]}, {"cell_type": "code", "metadata": {}, "source": ["# Map link magnitude and direction to numeric effect\n", "def to_numeric_mag(x):\n", "    try:\n", "        return float(x)\n", "    except Exception:\n", "        s = str(x).strip().lower()\n", "        return {'low':0.5,'medium':1.0,'high':1.5}.get(s, 1.0)\n", "impact_links = impact_links.copy()\n", "impact_links['mag_num'] = impact_links['impact_magnitude'].apply(to_numeric_mag)\n", "impact_links['dir_num'] = impact_links['impact_direction'].map({'positive':1,'negative':-1}).fillna(1)\n", "impact_links['effect'] = impact_links['mag_num'] * impact_links['dir_num']\n", "if 'event_date' in impact_links.columns:\n", "    impact_links['event_date'] = pd.to_datetime(impact_links['event_date'], errors='coerce')\n", "    start = pd.Timestamp(min(train_acc['year'].min(), usage_pct['year'].min()), 1, 1)\n", "    end = pd.Timestamp(2027,12,31)\n", "    idx = pd.date_range(start, end, freq='MS')\n", "    def ramp_effect(effect, lag_months, t_months):\n", "        if pd.isna(lag_months) or lag_months<=0: return effect\n", "        return effect * min(1.0, max(0.0, t_months/lag_months))\n", "    # Aggregate per-indicator monthly timelines\n", "    indicator_timelines = {}\n", "    for ind, grp in impact_links.groupby('related_indicator'):\n", "        s = pd.Series(0.0, index=idx)\n", "        for _, r in grp.iterrows():\n", "            lag = r.get('lag_months', 0) or 0\n", "            for t in idx:\n", "                t_months = (t - r['event_date']).days // 30\n", "                s.loc[t] += ramp_effect(r['effect'], lag, t_months)\n", "        indicator_timelines[ind] = s\n", "else:\n", "    indicator_timelines = {}\n", "print('Built indicator timelines:', len(indicator_timelines))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Scenarios and Forecasts (2025\u20132027)"]}, {"cell_type": "code", "metadata": {}, "source": ["scenarios = {\n", "    'pessimistic': {'trend_slope_mult':0.8, 'event_effect_mult':0.5},\n", "    'base':        {'trend_slope_mult':1.0, 'event_effect_mult':1.0},\n", "    'optimistic':  {'trend_slope_mult':1.2, 'event_effect_mult':1.5},\n", "}\n", "years_f = [2025, 2026, 2027]\n", "\n", "def event_delta(indicator, year):\n", "    # Difference between end-of-year modeled effect and 2024 end-of-year level\n", "    if indicator not in indicator_timelines: return 0.0\n", "    tl = indicator_timelines[indicator]\n", "    base_idx = tl.index.get_indexer([pd.Timestamp('2024-12-31')], method='nearest')[0]\n", "    y_idx = tl.index.get_indexer([pd.Timestamp(f'{year}-12-31')], method='nearest')[0]\n", "    return float(tl.iloc[y_idx] - tl.iloc[base_idx])\n", "\n", "rows = []\n", "for target, train, model, indicator_key in [\n", "    ('ACC_OWNERSHIP', train_acc, acc_model, 'ACC_OWNERSHIP'),\n", "    (usage_label, usage_pct, usage_model, 'USG_P2P_COUNT' if 'proxy' in usage_label else usage_label)\n", "]:\n", "    for scen, pars in scenarios.items():\n", "        # apply trend slope multiplier but keep intercept\n", "        adj_model = dict(model)\n", "        adj_model['slope'] = model['slope'] * pars['trend_slope_mult']\n", "        yhat, lo, hi = predict_years(adj_model, years_f)\n", "        for i, yr in enumerate(years_f):\n", "            base_pred = float(yhat[i])\n", "            # add event delta if available\n", "            ed = event_delta(indicator_key, yr) * pars['event_effect_mult']\n", "            with_events = base_pred + ed\n", "            rows.append({\n", "                'target': target, 'scenario': scen, 'year': yr,\n", "                'baseline_forecast': base_pred,\n", "                'with_events_forecast': with_events,\n", "                'lower_95': float(lo[i]), 'upper_95': float(hi[i]),\n", "                'event_delta': ed\n", "            })\n", "forecast_df = pd.DataFrame(rows)\n", "forecast_df\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Save Forecast Table"]}, {"cell_type": "code", "metadata": {}, "source": ["outp = Path('../reports/forecast_access_usage_2025_2027.csv')\n", "forecast_df.to_csv(outp, index=False)\n", "print(f'\u2713 Wrote {outp} (rows={len(forecast_df)})')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Scenario Visualization"]}, {"cell_type": "code", "metadata": {}, "source": ["def plot_target(target):\n", "    sub = forecast_df[forecast_df['target']==target]\n", "    fig, ax = plt.subplots(figsize=(9,4))\n", "    for scen, g in sub.groupby('scenario'):\n", "        ax.plot(g['year'], g['baseline_forecast'], '--', label=f'{scen} baseline')\n", "        ax.plot(g['year'], g['with_events_forecast'], '-', label=f'{scen} with events')\n", "    # uncertainty from base scenario (same band across scen for simplicity)\n", "    gbase = sub[sub['scenario']=='base']\n", "    ax.fill_between(gbase['year'], gbase['lower_95'], gbase['upper_95'], color='grey', alpha=0.2, label='95% CI (trend)')\n", "    ax.set_title(target)\n", "    ax.legend(ncol=2)\n", "    ax.grid(True, alpha=0.3)\n", "    plt.tight_layout()\n", "\n", "plot_target('ACC_OWNERSHIP')\n", "plot_target(usage_label)\n", "# Optional: save figure\n", "Path('../reports/figures').mkdir(parents=True, exist_ok=True)\n", "plt.savefig('../reports/figures/forecast_access_usage.png', dpi=200)\n", "print('\u2713 Saved scenario figure to ../reports/figures/forecast_access_usage.png')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Interpretation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Target: ACC_OWNERSHIP \u2014 baseline trend extrapolated with 95% CI; event-augmented scenarios adjust with ramped impacts from Task 3 link effects.\n", "- Target: Digital usage \u2014 if percent series not available, we use USG_P2P_COUNT as a usage proxy and forecast volumes with the same framework.\n", "- Scenarios: pessimistic (slower trend, muted events), base (current trajectory), optimistic (faster trend, stronger events).\n", "- Uncertainty: CI reflects historical fit error of the trend; it does not capture structural breaks or data revisions.\n", "- Limitations: sparse points (Findex), proxy for usage if percent unavailable, identification of overlapping events.\n", "- Largest impacts: events linked to account access and P2P volumes in Task 3 (e.g., major mobile money launches and policy changes) dominate the event deltas.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Export Interpretation (Markdown)"]}, {"cell_type": "code", "metadata": {}, "source": ["md = ['# Forecast Interpretation (Task 4)', '',\n", "      'This summarizes forecasts for 2025\u20132027 across scenarios.', '',\n", "      '## ACC_OWNERSHIP',\n", "      '- Baseline: linear trend with 95% CI based on residual RMSE.',\n", "      '- With events: adds ramped event deltas from impact links.', '',\n", "      '## Digital Payment Usage',\n", "      '- If percent series absent, we use USG_P2P_COUNT as a volume proxy.',\n", "      '- Scenarios scale trend slope and event deltas (0.8/1.0/1.2 and 0.5/1.0/1.5).', '',\n", "      '## Key Uncertainties',\n", "      '- Data sparsity (few Findex points), timing and magnitude of future events, policy risk.',\n", "      '- Proxy quality for usage when percent series is not present.', '',\n", "      '## Notes',\n", "      '- Replace the usage proxy with a percent indicator if/when available by setting usage_pct_codes above.',\n", "     ]\n", "outp = Path('../reports/forecast_interpretation.md')\n", "outp.write_text('\n'.join(md), encoding='utf-8')\n", "print(f'\u2713 Wrote {outp}')\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}